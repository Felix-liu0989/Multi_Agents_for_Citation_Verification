# å¤šç»´åº¦è®ºæ–‡åˆ†ç±»ç³»ç»Ÿ (Multi-Dimensional Paper Classification System)

ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šç»´åº¦è®ºæ–‡åˆ†ç±»ç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ„å»ºåˆ†ç±»ä½“ç³»ã€å¯ŒåŒ–èŠ‚ç‚¹ä¿¡æ¯ï¼Œå¹¶å¯¹å­¦æœ¯è®ºæ–‡è¿›è¡Œç»†ç²’åº¦åˆ†ç±»ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- **å¤šç»´åº¦åˆ†ç±»**ï¼šæ”¯æŒä»ä»»åŠ¡ã€æ•°æ®é›†ã€æ–¹æ³•è®ºã€è¯„ä¼°æ–¹æ³•ã€åº”ç”¨é¢†åŸŸç­‰å¤šä¸ªç»´åº¦å¯¹è®ºæ–‡è¿›è¡Œåˆ†ç±»
- **è‡ªåŠ¨å»ºå›¾**ï¼šåŸºäº LLM è‡ªåŠ¨æ„å»ºå’Œæ‰©å±•åˆ†ç±»ä½“ç³»çš„ DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰
- **èŠ‚ç‚¹å¯ŒåŒ–**ï¼šä¸ºæ¯ä¸ªåˆ†ç±»èŠ‚ç‚¹ç”Ÿæˆå…³é”®çŸ­è¯­å’Œæè¿°å¥å­ï¼Œå¢å¼ºè¯­ä¹‰ç†è§£
- **ç»†ç²’åº¦åˆ†ç±»**ï¼šå°†è®ºæ–‡é€’å½’ä¸‹æ²‰åˆ°æœ€åˆé€‚çš„å­èŠ‚ç‚¹ï¼Œå®ç°ç²¾å‡†åˆ†ç±»
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¸…æ™°çš„æ¨¡å—åˆ’åˆ†ï¼Œä¾¿äºæ‰©å±•å’Œç»´æŠ¤

## ğŸ“ é¡¹ç›®ç»“æ„

```
multi_dims/
â”œâ”€â”€ __init__.py          # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ builder.py           # DAG æ„å»ºå’Œæ‰©å±•
â”œâ”€â”€ enricher.py          # èŠ‚ç‚¹å¯ŒåŒ–ï¼ˆç”ŸæˆçŸ­è¯­å’Œå¥å­ï¼‰
â”œâ”€â”€ classifier.py        # è®ºæ–‡åˆ†ç±»ï¼ˆäº”ç»´é¡¶å±‚åˆ†ç±»ï¼‰
â”œâ”€â”€ pipeline.py          # æµæ°´çº¿ç¼–æ’
â””â”€â”€ taxo.py             # æ ¸å¿ƒ Node å’Œ DAG ç±»å®šä¹‰
```

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### å®Œæ•´æµæ°´çº¿

```
æ•°æ®åŠ è½½ â†’ äº”ç»´åˆ†ç±» â†’ å»ºå›¾ â†’ æ‰©å±•DAG â†’ å¯ŒåŒ– â†’ ç»†ç²’åº¦åˆ†ç±» â†’ ä¿å­˜ç»“æœ
```

### æ ¸å¿ƒæ¨¡å—

1. **å»ºå›¾æ¨¡å— (`builder.py`)**
   - `build_dags()`: æ ¹æ®ä¸»é¢˜å’Œç»´åº¦åˆ›å»ºå¤šä¸ª DAG æ ¹èŠ‚ç‚¹
   - `expand_all_dags()`: ä½¿ç”¨ BFS è°ƒç”¨ LLM æ‰©å±•å„ç»´åº¦çš„å­èŠ‚ç‚¹
   - `update_roots_with_labels()`: å°†äº”ç»´åˆ†ç±»ç»“æœå†™å›æ ¹èŠ‚ç‚¹

2. **å¯ŒåŒ–æ¨¡å— (`enricher.py`)**
   - `enrich_all_dags()`: ä¸ºæ‰€æœ‰èŠ‚ç‚¹ç”Ÿæˆå¸¸è¯†çŸ­è¯­å’Œå¥å­
   - æ”¯æŒä¿å­˜åˆ° JSON æ–‡ä»¶ä¾¿äºåç»­ä½¿ç”¨

3. **åˆ†ç±»æ¨¡å— (`classifier.py`)**
   - `label_papers_by_type()`: é¡¶å±‚äº”ç»´å¸ƒå°”åˆ†ç±»
   - å¤„ç† LLM è¿”å›æ ¼å¼çš„é²æ£’æ€§è§£æ

4. **æµæ°´çº¿æ¨¡å— (`pipeline.py`)**
   - `run()`: åŸºç¡€å»ºå›¾â†’å¯ŒåŒ–æµæ°´çº¿
   - `run_dag_to_classifier()`: å®Œæ•´åˆ†ç±»æµæ°´çº¿

## ğŸ› ï¸ å®‰è£…å’Œé…ç½®

### ç¯å¢ƒè¦æ±‚

```bash
conda activate -n taxo python==3.10
pip install -r requirements.txt
```

### é…ç½®å‚æ•°

```python
class Args:
    def __init__(self):
        self.topic = "natural language processing"  # ç ”ç©¶ä¸»é¢˜
        self.dimensions = [                         # åˆ†ç±»ç»´åº¦
            "tasks", 
            "datasets", 
            "methodologies", 
            "evaluation_methods", 
            "real_world_domains"
        ]
        self.llm = 'gpt'                           # ä½¿ç”¨çš„LLM
        self.init_levels = 2                       # åˆå§‹å±‚çº§
        self.max_density = 5                       # æœ€å¤§èŠ‚ç‚¹å¯†åº¦
        self.max_depth = 3                         # æœ€å¤§æ·±åº¦
        self.length = 512                          # æ–‡æœ¬é•¿åº¦
        self.dim = 768                             # å‘é‡ç»´åº¦
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºç¡€ä½¿ç”¨

```python
from multi_dims.pipeline import run
from model_definitions import initializeLLM

# åˆå§‹åŒ–å‚æ•°
args = Args()
args = initializeLLM(args)

# è¿è¡ŒåŸºç¡€æµæ°´çº¿ï¼ˆå»ºå›¾ + å¯ŒåŒ–ï¼‰
report = run(args)
```

### å®Œæ•´åˆ†ç±»æµæ°´çº¿

```python
from multi_dims.pipeline import run_dag_to_classifier
from datasets import load_dataset

# åŠ è½½æ•°æ®é›†
ds = load_dataset("your_dataset_path", split="train")

# å‡†å¤‡è®ºæ–‡é›†åˆ
paper_collection = {}
for i, paper in enumerate(ds):
    paper_collection[i] = Paper(
        i, 
        paper['title'], 
        paper['abstract'], 
        label_opts=args.dimensions, 
        internal=True
    )

# è¿è¡Œå®Œæ•´åˆ†ç±»æµæ°´çº¿
roots, dags = run_dag_to_classifier(args, paper_collection)
```

## ğŸ“Š è¾“å‡ºæ–‡ä»¶

ç³»ç»Ÿä¼šåœ¨ `runs/{topic_name}/` ç›®å½•ä¸‹ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

### åˆ†ç±»ç»“æœ
- `paper_labels.json`: æ¯ç¯‡è®ºæ–‡çš„ç»†ç²’åº¦æ ‡ç­¾
- `grouped_papers.json`: æŒ‰ç»´åº¦åˆ†ç»„çš„è®ºæ–‡
- `paper_meta.json`: è®ºæ–‡å…ƒä¿¡æ¯ï¼ˆæ ‡é¢˜ã€æ‘˜è¦ï¼‰

### åˆ†ç±»ä½“ç³»
- `final_taxo_*.json`: å„ç»´åº¦çš„åˆ†ç±»ä½“ç³»æ ‘ï¼ˆJSONæ ¼å¼ï¼‰
- `final_taxo_*.txt`: å„ç»´åº¦çš„åˆ†ç±»ä½“ç³»æ ‘ï¼ˆå¯è¯»æ ¼å¼ï¼‰

### å¯ŒåŒ–ä¿¡æ¯
- `enriched_phrases.json`: èŠ‚ç‚¹å…³é”®çŸ­è¯­
- `enriched_sentences.json`: èŠ‚ç‚¹æè¿°å¥å­

### ç»Ÿè®¡æŠ¥å‘Š
- `pipeline_report.json`: æµæ°´çº¿è¿è¡Œç»Ÿè®¡

## ğŸ“ è¾“å‡ºæ ¼å¼ç¤ºä¾‹

### è®ºæ–‡æ ‡ç­¾ (`paper_labels.json`)
```json
{
  "0": {
    "tasks": ["text_classification", "sentiment_analysis"],
    "datasets": ["imdb", "sst"],
    "methodologies": ["transformer", "bert"]
  }
}
```

### åˆ†ç»„è®ºæ–‡ (`grouped_papers.json`)
```json
{
  "tasks": [
    {
      "paper_id": 0,
      "title": "BERT for Sentiment Analysis",
      "abstract": "This paper presents..."
    }
  ]
}
```

### åˆ†ç±»ä½“ç³» (`final_taxo_tasks.json`)
```json
{
  "label": "tasks",
  "level": 0,
  "papers": {...},
  "children": {
    "text_classification": {
      "label": "text_classification",
      "level": 1,
      "children": {...}
    }
  }
}
```

## ğŸ”§ æ ¸å¿ƒç®—æ³•

### 1. DAG æ„å»º
- ä½¿ç”¨ BFS éå†æ‰©å±•èŠ‚ç‚¹
- æ”¯æŒå®½åº¦æ‰©å±•ï¼ˆ`expandNodeWidth`ï¼‰å’Œæ·±åº¦æ‰©å±•ï¼ˆ`expandNodeDepth`ï¼‰
- åŠ¨æ€è°ƒæ•´æ‰©å±•ç­–ç•¥

### 2. è®ºæ–‡åˆ†ç±»
- é¡¶å±‚äº”ç»´å¸ƒå°”åˆ†ç±»ç¡®å®šè®ºæ–‡æ‰€å±ç»´åº¦
- é€’å½’ä¸‹æ²‰åˆ°å­èŠ‚ç‚¹å®ç°ç»†ç²’åº¦åˆ†ç±»
- ä½¿ç”¨é˜Ÿåˆ—ç®¡ç†åˆ†ç±»è¿‡ç¨‹

### 3. èŠ‚ç‚¹å¯ŒåŒ–
- ä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆ 20 ä¸ªå…³é”®çŸ­è¯­
- ç”Ÿæˆ 10 ä¸ªæè¿°å¥å­å¢å¼ºè¯­ä¹‰ç†è§£
- æ”¯æŒæ‰¹é‡å¤„ç†å’Œå¢é‡æ›´æ–°

## ğŸ¯ åº”ç”¨åœºæ™¯

1. **æ–‡çŒ®ç»¼è¿°ç”Ÿæˆ**ï¼šåŸºäºåˆ†ç±»ç»“æœç”Ÿæˆç»“æ„åŒ–çš„ç›¸å…³å·¥ä½œ
2. **çŸ¥è¯†å›¾è°±æ„å»º**ï¼šæ„å»ºå­¦æœ¯é¢†åŸŸçš„çŸ¥è¯†å›¾è°±
3. **è®ºæ–‡æ¨èç³»ç»Ÿ**ï¼šåŸºäºå¤šç»´åº¦åˆ†ç±»è¿›è¡Œç²¾å‡†æ¨è
4. **ç ”ç©¶è¶‹åŠ¿åˆ†æ**ï¼šåˆ†æä¸åŒç»´åº¦çš„ç ”ç©¶çƒ­ç‚¹å’Œå‘å±•è¶‹åŠ¿

## ğŸ› å¸¸è§é—®é¢˜

### JSON è§£æé”™è¯¯
- **é—®é¢˜**ï¼šLLM è¿”å› `True/False` è€Œé `true/false`
- **è§£å†³**ï¼šä½¿ç”¨ `_safe_json_load()` è¿›è¡Œæ ¼å¼è½¬æ¢

### API è°ƒç”¨æ ¼å¼é”™è¯¯
- **é—®é¢˜**ï¼š`messages` å‚æ•°æ ¼å¼ä¸æ­£ç¡®
- **è§£å†³**ï¼šä½¿ç”¨ `constructPrompt()` ç”Ÿæˆæ­£ç¡®æ ¼å¼

### æ ‡ç­¾é‡å¤é—®é¢˜
- **é—®é¢˜**ï¼šåŒä¸€è®ºæ–‡è¢«å¤šæ¬¡åˆ†ç±»å¯¼è‡´æ ‡ç­¾é‡å¤
- **è§£å†³**ï¼šä½¿ç”¨ `list(set(p.labels[dim]))` å»é‡


## TODO List
- åˆ©ç”¨æ–‡çŒ®æ ‘ç”Ÿæˆå¤§çº²
- æ ¹æ®å¤§çº²ä¸ºæ¯ä¸ªéƒ¨åˆ†è¿­ä»£ç”Ÿæˆ
- å®ç°å‡ ä¸ªéƒ¨åˆ†çš„å¼‚æ­¥å¹¶è¡Œ
- è¯„ä¼°æŒ‡æ ‡è·‘é€š

- å¤§çº²ä¸­åŒ…å«ä¸¤åˆ°ä¸‰ä¸ªè¦ç‚¹
- ç”Ÿæˆçš„å¤§çº²ä¹Ÿæ˜¯ä¸€ä¸ªæœ‰å‘æ— ç¯å›¾
- ç”Ÿæˆçš„å†…å®¹ä¾‹å­å¦‚ä¸‹ï¼štask-methodology-evalä¸‰å…ƒç»„
- æ ¹æ®ä¸‰å…ƒç»„ç”Ÿæˆsummaryï¼Œï¼ˆä»¥ä¸‹å¯é€‰ï¼‰ç”Ÿæˆä¸‰æ¬¡ï¼Œæ‰“åˆ†
- æŒ‚é åœ¨æŸä¸ªè¦ç‚¹ä¸‹
- è¿­ä»£å¯¹æ¯”

