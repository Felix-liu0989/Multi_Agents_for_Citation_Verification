# 1. 

对context进行分句，每个句子有一个标志<C{i}>

```python
sentences = text_split_by_punctuation(context,return_dict = True)
passage = ""

for i,c in enumerate(sentences):
    start,end = c['start_idx'],c['end_idx']
    assert c['content'] == context[start:end],c
    end = sentences[i+1]['start_idx'] if i < len(sentences) - 1 else len(context)
    passage += f"<C{i}>"+context[start:end]
```

生成引用之后，进行后处理

把论述和引用分开，以字典来储存



```python
def postprocess(answer,context,sents):
    # 将context按句子分割成多个句子
    chunks = []
    for k,s in enumerate(sents):
        s_start,s_end = s['start_idx'],s['end_idx']
        assert s['content'] == context[s_start:s_end],s
        s_end = sents[k+1]['start_idx'] if k < len(sents) - 1 else s['end_idx']
        chunks.append({
            'content':context[s_start:s_end],
            'start_idx':s_start,
            'end_idx':s_end,
            'c_idx':s['c_idx']
        } 
    )
    
    res = []
    pos = 0
    while True:
        start = answer.find("<statement>",pos)
        if start == -1:
            start = len(answer)
        end = answer.find("</statement>",start)
        statement = answer[pos:start]
        if len(statement.strip()) > 5:
            res.append(
                {
                    "statement":statement,
                    "citation":[]
                }
            )
        if end == -1:
            break
        
        statement = answer[start+len("<statement>"):end]
        
        if len(statement.strip()) > 0:
            statement,citations = get_citations(statement,sents)
            res.append(
                {
                    "statement":statement,
                    "citation":citations
                }
            )
        pos = end + len("</statement>")
        
    return res

def get_citations(statement, sents):
    c_texts = re.findall(r'<cite>(.*?)</cite>', statement, re.DOTALL)
    c_texts = [c_text.replace('C', '') if 'C' in c_text else c_text for c_text in c_texts]
    spans = sum([re.findall(r"\[([0-9]+\-[0-9]+)\]", c_text, re.DOTALL) for c_text in c_texts], [])
    statement = re.sub(r'<cite>(.*?)</cite>', '', statement, flags=re.DOTALL)
    merged_citations = []
    for i, s in enumerate(spans):
        try:
            st, ed = [int(x) for x in s.split('-')]
            if st > len(sents) - 1 or ed < st:
                continue
            st, ed = max(0, st), min(ed, len(sents)-1)
            assert st <= ed, str(c_texts) + '\t' + str(len(sents))
            if len(merged_citations) > 0 and st == merged_citations[-1]['ed_sent'] + 1:
                merged_citations[-1].update({
                    "ed_sent": ed,
                    'end_char': sents[ed]['end'],
                    'cite': ''.join([x['content'] for x in sents[merged_citations[-1]['st_sent']:ed+1]]),
                })
            else:
                merged_citations.append({
                    "st_sent": st,
                    "ed_sent": ed,
                    "start_char":  sents[st]['start_idx'],
                    'end_char': sents[ed]['end_idx'],
                    'cite': ''.join([x['content'] for x in sents[st:ed+1]]),
                })
        except:
            print(c_texts, len(sents), statement)
            raise
    return statement, merged_citations[:3]
```

recall评估

```python
def score_recall(question, answer, statements_with_citations):
    scores, usages = [], []
    for js in statements_with_citations:
        statement, citations = js['statement'], js['citation']
        matched_citations = [c['cite'] for c in citations]
        if len(matched_citations) > 0:
            context = '\n\n'.join(matched_citations).strip()
            score, output, usage = is_support(question, statement, context)
            usages.append(usage)
            js.update({
                "support_output": output,
                "support_score": score,
            })
            if score is None:
                print("ERROR\tUnexcept support output: ", statement + '\t>>\t' + output)
                raise NotImplementedError
            else:
                scores.append(score)
        else:
            score, output, usage = need_citation(question, answer, statement)
            usages.append(usage)
            js.update({
                "support_output": output,
                "support_score": 1 - score if score is not None else None,
            })
            if score is None:
                print("ERROR\tUnexcept need_citation output: ", output)
                raise NotImplementedError
            else:
                scores.append(1-score)
    if len(scores) == 0:
        return 0, statements_with_citations, usages
    else:
        return np.mean(scores), statements_with_citations, usages
        
```

```python
def is_support(question, statement, context):
    if context == "":
        return 0, "No matched citation", None
    prompt = support_prompt_template.format(cat_question_statement_context(question, statement, context))
    for t in range(5):
        msg = [{'role': 'user', 'content': prompt}]
        output = query_llm(msg, model=GPT_MODEL, temperature=0 if t == 0 else 1, max_new_tokens=10, stop="Analysis:", return_usage=True)
        if isinstance(output, tuple):
            output, usage = output
            score = support_level_to_score(output)
        else:
            score, usage = None, None
        if score is None:
            print("Unexcept support output: ", output)
            if 'Trigger' in output:
                break
            continue
        else:
            break
    return score, output, usage
        
```

Leveraging LLMs, we formulate natural language feedback F for each dimension, predicated upon the respective evalu ation outcomes. Using the initial output Y along with the feedback F, the model M iteratively re f ines its output, stopping when it determines that additional refinement is no longer needed.





## 2025/7/3

╭─ build_dags ──┬── expand_all_dags (BFS 扩) ─┬── enrich_all_dags  (20 词 + 10 句)
│                │                             └── save enriched_xxx.json
│                └──(可选) save 初始/扩展 DAG
└──  label_papers_by_type  (五维) ──► update_roots_with_labels
    ↓
 classify_dag (递归到子节点)  ←  可选：先用富化短语做 Top-k 检索再喂 LLM